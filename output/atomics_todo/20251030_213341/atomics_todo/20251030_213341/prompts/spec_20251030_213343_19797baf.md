# Prompt

## System
You are a helpful AI assistant specialized in Verus formal verification.

## Instruction
You are an expert in Verus (a Rust-based verification framework). Your task is to replace every occurrence of `// TODO: add proof` or `// TODO: add invariants` with appropriate proof blocks or loop invariants that help Verus verify the program. If invariants already exist, reconsider the invariants and edit them if necessary.

‚ö†Ô∏è **CRITICAL #1**: For functions that update `Seq<T>` views (like `set_bit`, `set_element`), you MUST use the `assert_seqs_equal!` macro in your proof block. DO NOT try to prove sequence equality manually with `assert forall` - it will fail! See Section 2 for details.

‚ö†Ô∏è **CRITICAL #2**: When adding loop invariants, you MUST check Section 3's mandatory checklist and follow the patterns. Most verification failures come from missing bridge invariants or missing region invariants. DO NOT skip these checks.

Follow these guidelines carefully:

## Quickstart

- Seq<T> update: modify concrete state first, then in `proof { ... }` call `assert_seqs_equal!(self.view(), old(self).view().update(index as int, value))`.
- Loops with view()-based postconditions: add a processed-region bridge invariant, prove only the new segment each iteration, and include a `decreases` clause.
- Repeat relevant preconditions inside invariants (ordering, bounds, distinctness, etc.).
- Keep lengths stable; add explicit length-preservation ensures when mutating elements.
- Pair this guide with few-shots in `src/examples/input-proof/` ‚Üî `src/examples/output-proof/` (see `ex_chunk_bridge.rs`).

## Table of Contents

- 1. Core Rules
  - Seq<T> Update Operations (MOST IMPORTANT)
  - Length Preservation Postconditions
  - Proof Block Structure
- 2. Loop Invariants
  - Mandatory Checklist
  - Inherit Precondition Properties
  - Decreases Clauses for Loop Termination
  - Pattern: Recognizing When Bridge Invariants Are Needed
  - Strengthening Loop Invariants for Array Access
  - CRITICAL: Multi-Region Invariants for Two-Pointer Algorithms
  - Pattern: Chunked-to-Bit Bridging for Bitwise Loops
- 3. Other Proof Techniques
- 4. Common Proof Locations
- 5. Constraints
- 6. Verification

## 1. Core Rules

### Proof Block Structure

- For regular functions (`fn` or `pub fn`): Add proof blocks using the syntax `proof { ... }`
- For proof functions (`proof fn`): Write assertions directly in the function body - DO NOT use `proof { ... }` blocks
- Each proof block should be focused and minimal, containing only what's needed

### Seq<T> Update Operations (MOST IMPORTANT)

**‚ö†Ô∏è USE `assert_seqs_equal!` MACRO - DO NOT USE `assert forall`**

When a function updates a `Seq<T>` view (e.g., `set_bit`, `set_element`, `insert`, `update`), you MUST use the `assert_seqs_equal!` macro **AFTER the actual modification**:

```rust
// First do the actual modification
self.bits.set(seq_index, bv_new);

// Then prove it worked with assert_seqs_equal!
proof {
    assert_seqs_equal!(
        self.view(),
        old(self).view().update(index as int, value)
    );
}
```

**CRITICAL**: The `assert_seqs_equal!` macro must come AFTER the state modification, not before!

**Common mistakes to AVOID**:
- ‚ùå DON'T write: `assert forall|i: int| ...` (this will fail!)
- ‚ùå DON'T try to prove sequence equality manually
- ‚ùå DON'T skip this macro and leave proof block empty

**When to use this**:
- Any function that modifies exactly one position in a Seq-based view
- After calling operations like `self.data.set(...)` to update a single element
- When postcondition mentions `old(self)@.update(...)`
- When the function semantics are "change element at index i, keep rest unchanged"

**This macro automatically**:
- Proves sequence lengths match
- Proves element-wise equality with proper triggers
- Handles the connection between low-level field updates and high-level view updates

### Bit-Vector Macros and View Bridging (u64 chunks ‚Üî Seq<bool>)

When a data structure stores bits in `u64` chunks but exposes a `Seq<bool>` via `spec fn view(&self)`, follow these rules:

- Prefer `@` over `.view()` in proofs and invariants (e.g., `self@[i]`, `result@[k]`).
- Use the bit-vector lemmas for chunk-level correctness:
  - `set_bit64_proof(new, old, idx, bit)` after computing the updated `u64` value.
  - `bit_or_64_proof(u1, u2, or_int)` after computing `or_int = u1 | u2`.
- Use `get_bit64!` to connect a `u64` chunk to boolean bits in `Seq<bool>`:
  - Example: `get_bit64!(self.bits@[i / 64], (i % 64) as u64)`.
- For per-iteration proof of a newly produced chunk (e.g., in a loop), add a proof block:

```rust
proof {
    assert forall|off: int| 0 <= off && off < 64 ==>
        result@[(i as int) * 64 + off]
            == (self@[(i as int) * 64 + off] || bm@[(i as int) * 64 + off])
    by {
        // justified by bit_or_64_proof(u1, u2, or_int)
    }
}
```

Syntax and arithmetic constraints:

- Use `==>` (not the word `implies`) in `assert forall`.
- Avoid chained inequalities. Rewrite `0 <= k < B` as `0 <= k && k < B`.
  - **CRITICAL**: Comparison operators (`<=`, `>=`, `<`, `>`, `==`, `!=`) are single tokens - NEVER split them with spaces!
  - ‚úÖ Correct: `0 <= x && x <= n` (proper `<=` operator)
  - ‚ùå WRONG: `0 <= x && x < = n` (broken operator with space)
  - ‚úÖ Correct: `a >= b && b > c` (proper operators)
  - ‚ùå WRONG: `a > = b && b > c` (broken operator with space)
- Parenthesize casts in products: `(i as int) * 64`.

### Length Preservation Postconditions

For mutation methods that modify array/vector elements but don't change the container size, explicitly add length preservation to postconditions:

```rust
fn update_element(&mut self, index: ElementIndex, value: ElementType)
    requires
        index < old(self)@.len(),
    ensures
        self@ == old(self)@.update(index as int, value),
        self.data@.len() == old(self).data@.len(),
```

Why: When mutation methods are called sequentially, Verus needs to track that container lengths remain unchanged. Without explicit postconditions, Verus cannot prove that subsequent calls satisfy their preconditions.

General pattern: For any `&mut self` method that (1) accesses elements via indices, (2) does NOT call `push`, `pop`, `resize`, etc., (3) only modifies element values ‚Üí Always add `self.container@.len() == old(self).container@.len()`.

## 2. Loop Invariants

- Start with type invariant usage (if exists): For methods in `impl` blocks, begin with:
  * `use_type_invariant(&*self);` for reference receivers
  * `use_type_invariant(self);` for value receivers
- Carefully review all existing lemmas defined in the file and invoke each one that is relevant to the current proof context, using the syntax `lemma_name(arg1, arg2, ...)`.
  * For example, if there are lemmas about sequence bounds or modular arithmetic, call them as needed, such as `lemma_mod_auto(self.vt.len() as int)`.
  * For lemmas about sequence properties, use the appropriate generic syntax, e.g., `broadcast use group_seq_properties`.
  * When reasoning about sequences or specifications, ensure that all applicable modular arithmetic and sequence-related lemmas from the file are called to support your proof.
- Use assertions strategically with `assert(condition)`
- When helpful, use the `by(...)` syntax for proof steps:
  * `by(nonlinear_arith)` for arithmetic reasoning
  * `by { ... }` for explicit proof steps

### Mandatory Checklist

1. ‚úì Does the struct have a `spec fn view(&self)` or similar abstraction?
2. ‚úì Is the postcondition expressed using `view()` or other spec functions?
3. ‚úì Does the loop modify the concrete representation (fields, arrays)?
4. ‚úì Are there function preconditions (sorted, non-negative, etc.)?
5. ‚úì Does the loop process from multiple positions (two pointers, dual-end)?

**IF YES to questions 1-3:** You MUST add bridge invariants (see Section 3.2.2)
**IF YES to question 4:** You MUST inherit preconditions into invariants (see below)
**IF YES to question 5:** You MUST add invariants for ALL regions (see Section 3.3)

When adding loop invariants (marked by `// TODO: add invariants`), include:

- Identify and add invariants for EVERY variable that is READ in the loop:
  * For scalar variables (e.g., x, y)
  * For array/vector elements (e.g., x[k], v[i])
  * Include invariants about their initial values
- Identify and add invariants for EVERY variable that is WRITTEN in the loop:
  * For direct assignments (e.g., y = ...)
  * For vector/array updates (e.g., v.set(..., ...))
  * Repeat relevant invariants even if specified earlier
- Fully utilize spec functions and proof functions in the invariants

### Inherit Precondition Properties into Loop Invariants

When a loop's correctness depends on properties from the function's preconditions, those properties MUST be explicitly repeated in the loop invariants, even though they are "obviously" true from context.

**Common precondition properties to inherit:**

1. **Ordering properties**: `forall|i: int, j: int| 0 <= i <= j < array.len() ==> array[i] <= array[j]`
2. **Non-negative values**: `forall|i: int| 0 <= i < array.len() ==> array[i] >= 0`
3. **Distinct elements**: `forall|i: int, j: int| 0 <= i < j < array.len() ==> array[i] != array[j]`
4. **Bounded values**: `forall|i: int| 0 <= i < array.len() ==> array[i] < MAX_VALUE`
5. **Structural properties**: Any property about the structure of data that the algorithm relies on

**Abstract Pattern:**
```rust
fn algorithm(data: &DataStructure, target: ValueType) -> (result: ResultType)
    requires
        precondition_property_1(data),  // e.g., ordering, uniqueness, etc.
        precondition_property_2(data, target),
{
    // ... initialization ...
    while loop_condition
        invariant
            loop_bounds_invariant,
            precondition_property_1(data),  // ‚Üê MUST REPEAT preconditions!
            loop_correctness_invariant,
        decreases termination_metric
    {
        // loop body that relies on precondition_property_1
    }
}
```

**Why this matters**: Verus does not automatically assume preconditions remain true inside loops. Without explicitly stating these properties in invariants, Verus cannot use them to reason about why the loop maintains correctness (e.g., why narrowing ranges, partitioning data, or updating indices preserves desired properties).

### Decreases Clauses for Loop Termination

Every loop MUST have a `decreases` clause to prove termination:

```rust
while condition
    invariant
        // ... your invariants ...
    decreases expression  // ‚Üê REQUIRED
{
    // loop body
}
```

**Common patterns:**

1. **Incrementing counter** (`while i < n`):
   ```rust
   decreases n - i
   ```

2. **Decrementing counter** (`while i > 0`):
   ```rust
   decreases i
   ```

3. **Binary search / narrowing range** (`while i1 < i2`):
   ```rust
   decreases i2 - i1
   ```

4. **Narrowing range with != condition** (`while i1 != i2`):
   ```rust
   decreases i2 - i1  // Ensure i1 and i2 converge
   ```

5. **Complex expressions** - use the value that strictly decreases each iteration

**The decreases expression must:**
- Be non-negative (type `int` or `nat`)
- Strictly decrease on each loop iteration
- Prove the loop eventually terminates

**Key insight for narrowing range algorithms**: When maintaining a search range [i1, i2], ensure the invariant states that the target exists within the **current range** [i1, i2], not just somewhere in the entire collection. For example:
- ‚ùå Weak: `exists|i: int| 0 <= i < v.len() && v[i] == k`
- ‚úÖ Strong: `exists|i: int| i1 <= i <= i2 && v[i] == k`

This ensures that when the loop exits with i1 == i2, the invariant directly proves the postcondition.

### Pattern: Recognizing When Bridge Invariants Are Needed

**Before writing loop invariants, check:**
1. Does the data structure have a `spec fn view(&self)` or similar abstraction function?
2. Is the postcondition expressed in terms of `view()` rather than raw fields?
3. Does the loop modify the underlying concrete representation?

**If YES to all three ‚Üí You MUST add bridge invariants** (see Section 3.2.2 below)

### CRITICAL: Multi-Region Invariants for Two-Pointer Algorithms

When an algorithm processes an array/sequence from multiple positions (e.g., from both ends, or with multiple cursors), you MUST add separate invariants for EACH region.

**Pattern: Dual-end processing (moving from both ends toward middle)**

When processing indices from both ends (e.g., `left` moving right, `right` moving left):

```rust
for cursor in 0..midpoint
    invariant
        // Bounds
        0 <= cursor <= midpoint,
        cursor <= length - cursor,
        // Region 1: Left side [0, cursor) - already processed
        forall|i: int| 0 <= i < cursor ==>
            property_holds_for_processed(v[i], original[i]),
        // Region 2: Middle [cursor, length-cursor) - not yet touched
        forall|i: int| cursor <= i < length - cursor ==>
            v[i] == original[i],
        // Region 3: Right side [length-cursor, length) - already processed  ‚Üê CRITICAL!
        forall|i: int| length - cursor <= i < length ==>
            property_holds_for_processed(v[i], original[i]),
```

**Why all three regions matter:**
- When loop exits at `cursor = midpoint`
- Left covers `[0, midpoint)`
- Middle becomes `[midpoint, midpoint)` = **empty**
- Right covers `[midpoint, length)`
- Together: **full coverage** of `[0, length)`

**Common mistake**: Forgetting the third invariant for the right/back region. Without it, Verus has no information about what happened to elements processed from the other end, causing postcondition failures.

**Pattern: Multiple cursors/partitions**

For algorithms with multiple moving boundaries (e.g., partitioning, quicksort-style):
```rust
while condition
    invariant
        // All cursor positions and their relationships
        0 <= cursor1 <= cursor2 <= cursor3 <= length,
        // Region 1: [0, cursor1) - elements with property A
        forall|i: int| 0 <= i < cursor1 ==> has_property_A(v[i]),
        // Region 2: [cursor1, cursor2) - elements with property B
        forall|i: int| cursor1 <= i < cursor2 ==> has_property_B(v[i]),
        // Region 3: [cursor2, cursor3) - elements with property C
        forall|i: int| cursor2 <= i < cursor3 ==> has_property_C(v[i]),
        // Region 4: [cursor3, length) - unprocessed
        // (may not need invariant if no property required yet)
```

**General principle**: If your algorithm creates N distinct regions during execution, you typically need N-1 to N invariants describing what's true in each region.

### Strengthening Loop Invariants for Array Access

When loops access arrays/vectors using loop variables, Verus needs strong invariants to prove bounds safety:

1. **Track array lengths explicitly**: If accessing arrays/vectors using loop variables, add:
   ```rust
   n == self.data@.len(),
   n == other.data@.len(),
   ```
   where `n` is the loop bound. This helps Verus prove `i < array.len()` at each access.

2. **Add "bridge invariants" connecting concrete and abstract representations**:

**‚ö†Ô∏è CRITICAL PATTERN - Most common cause of verification failure!**

If the struct has `spec fn view(&self)` and the postcondition mentions `view()`, you MUST add TWO invariants:

   When a data structure has both:
   - Concrete representation (e.g., `data: Vec<ChunkType>`)
   - Abstract specification via `spec fn view(&self) -> Seq<ElementType>`

   You MUST add invariants at BOTH levels:

   **Raw level** (concrete):
   ```rust
   forall|j: int| 0 <= j < i ==>
       result.data@[j] == combine_chunks(self.data@[j], other.data@[j])
   ```

   **Spec level** (abstract) - **REQUIRED to prove postconditions about view()**:
   ```rust
   forall|k: int| 0 <= k < i * ITEMS_PER_CHUNK ==>
       extract_from_chunks(result.data@, k) ==
       combine_elements(
           extract_from_chunks(self.data@, k),
           extract_from_chunks(other.data@, k)
       )
   ```

   **Key insight**: The spec-level invariant should use the SAME EXPRESSION as the view() function definition. This creates a direct bridge from concrete state to abstract spec, allowing Verus to prove postconditions stated in terms of view().

   Without the spec-level invariant, Verus cannot connect loop progress to postconditions about view().

   **STEP-BY-STEP RECIPE (DO THIS EVERY TIME):**

   1. **Find** the `spec fn view(&self)` definition in the struct
   2. **Copy** the exact expression used inside `Seq::new(...)`
   3. **Add raw-level invariant** (about concrete fields):
      ```rust
      forall|j: int| 0 <= j < i ==> result.data@[j] == combine(self.data@[j], other.data@[j])
      ```
   4. **Add bridge invariant** (REQUIRED - copy the view() expression):
      ```rust
      forall|k: int| 0 <= k < i * CHUNK_SIZE ==>
          expression_from_view(result.data@, k) ==
          expected_result(expression_from_view(self.data@, k),
                         expression_from_view(other.data@, k))
      ```



3. **Add proof blocks INSIDE loops**: After modifying data structures in a loop, add proof blocks to establish invariants for the new iteration:
   ```rust
   result = DataStructure { data: new_data };
   proof {
       assert forall|k: int| i * ITEMS_PER_CHUNK <= k < (i + 1) * ITEMS_PER_CHUNK implies
           result.view()[k] == expected_value(self.view()[k], other.view()[k])
       by {
           // Use relevant lemmas and properties here
       }
   }
   ```

### Pattern: Chunked-to-Bit Bridging for Bitwise Loops

When arrays/vectors store data in fixed-size chunks (e.g., machine words), but the `view()` exposes a per-element/bit `Seq<T>` (e.g., `Seq<bool>`), you must bridge from chunk-level updates to bit-level postconditions.

**Goal**: Prove a spec-level property for all elements/bits, while the loop processes one chunk per iteration.

**Invariants (before each iteration i):**
- 0 <= i <= chunks
- Result growth (if constructing a new buffer): `result_bits@.len() == i`
- Lengths are fixed: `self@.len() == n`, `other@.len() == n`
- Spec-level bridge for processed region:
  ```rust
  forall|k: int| #![auto]
      0 <= k < i * CHUNK_SIZE ==>
      result@[k] == combine(self@[k], other@[k])
  ```

**After producing the next chunk (at index i):**
Place a proof block that re-establishes only the new segment `[i*CHUNK_SIZE, (i+1)*CHUNK_SIZE)`:
```rust
proof {
    assert forall|b: int| 0 <= b < CHUNK_SIZE implies
        result@[i*CHUNK_SIZE + b] == combine(self@[i*CHUNK_SIZE + b], other@[i*CHUNK_SIZE + b])
    by {
        // Unfold the view() mapping between (chunk, bit) and flat index
        // Let r_chunk = result_chunks@[i];
        // Let a_chunk = self_chunks@[i];
        // Let b_chunk = other_chunks@[i];
        // Use a chunk-level lemma, e.g., `chunk_op_lemma(a_chunk, b_chunk, r_chunk)`
        // that shows element/bit b of r_chunk equals combine(bit b of a_chunk, bit b of b_chunk).
    }
}
```

**Tips**
- Split proof into two regions each iteration: processed-old `[0, i*CHUNK_SIZE)` carried by the invariant, plus new `[i*CHUNK_SIZE, (i+1)*CHUNK_SIZE)` proved in the by-block.
- Keep arithmetic in `int` for invariants and proofs; perform casts only at concrete operation sites.
- Add a `decreases` clause, e.g., `decreases chunks - i`.

**Postconditions** (example):
```rust
ensures
    ret@.len() == self@.len(),
    forall|k: int| #![auto] 0 <= k < ret@.len() ==> ret@[k] == combine(self@[k], other@[k])
```

**Common mistakes to avoid**
- Writing a single large `forall k < (i+1)*CHUNK_SIZE` without splitting; prove only the new segment each iteration.
- Mixing `nat` and `int` in indices; use `int` in specs, cast at the boundary.
- Placing the per-segment proof before the actual mutation; the proof must come after updating the concrete state.

#### Example template (pair with few-shot)

Use this as a minimal template and pair it with the few-shot example files in `src/examples/input-proof/ex_chunk_bridge.rs` and `src/examples/output-proof/ex_chunk_bridge.rs`:

```rust
let mut i: usize = 0;
while i < chunks
    invariant
        0 <= i as int <= chunks as int,
        out_chunks@.len() == i as int,
        a@.len() == b@.len() == len_bits as int,
        forall|k: int| #![auto]
            0 <= k < i as int * CHUNK_SIZE ==>
            view_from(out_chunks@, len_bits as int)[k] == combine(a@[k], b@[k]),
    decreases chunks as int - i as int
{
    let a_chunk = a.chunks[i];
    let b_chunk = b.chunks[i];
    let r_chunk = chunk_op(a_chunk, b_chunk);
    out_chunks.push(r_chunk);

    proof {
        assert forall|off: int| 0 <= off < CHUNK_SIZE implies
            view_from(out_chunks@, len_bits as int)[i as int * CHUNK_SIZE + off]
                == combine(a@[i as int * CHUNK_SIZE + off],
                           b@[i as int * CHUNK_SIZE + off])
        by { chunk_op_lemma(a_chunk, b_chunk, r_chunk, off); }
    }

    i += 1;
}
```

Notes:
- Keep names generic (`combine`, `chunk_op`, `chunk_op_lemma`, `CHUNK_SIZE`).
- Follow the order: concrete mutation ‚Üí proof of the new segment.

## 3. Other Proof Techniques

- Start with type invariant usage (if exists): For methods in `impl` blocks, begin with:
  * `use_type_invariant(&*self);` for reference receivers
  * `use_type_invariant(self);` for value receivers
- Carefully review all existing lemmas defined in the file and invoke each one that is relevant to the current proof context, using the syntax `lemma_name(arg1, arg2, ...)`.
  * For example, if there are lemmas about sequence bounds or modular arithmetic, call them as needed, such as `lemma_mod_auto(self.vt.len() as int)`.
  * For lemmas about sequence properties, use the appropriate generic syntax, e.g., `broadcast use group_seq_properties`.
  * When reasoning about sequences or specifications, ensure that all applicable modular arithmetic and sequence-related lemmas from the file are called to support your proof.
- Use assertions strategically with `assert(condition)`
- When helpful, use the `by(...)` syntax for proof steps:
  * `by(nonlinear_arith)` for arithmetic reasoning
  * `by { ... }` for explicit proof steps

## 4. COMMON PROOF LOCATIONS

- At function start
- Before loops
- At loop start
- At loop end
- Before key operations
- After key operations

## 6. CONSTRAINTS

- DO NOT modify any code outside of proof blocks, invariant declarations, or postconditions
- You MAY add postconditions to `ensures` clauses (e.g., length preservation)
- DO NOT change function signatures (parameters, return types), types, or preconditions
- DO NOT add new functions or types
- If no TODO markers exist, return code unchanged

## 7. VERIFICATION

- Ensure all proof blocks and invariants compile under Verus
- Remove all TODO placeholders

Return the ENTIRE file with your changes ‚Äì not a diff or partial snippet.



# Verus Common Knowledge

## Important Notes
- ALWAYS use parentheses whenever possible for clarity!
- Don't delete existing non-buggy `#[trigger]`!
- Don't change "unwind" to `(unwind) as bool`!
- Return the complete modified Rust code in your response without explanations.
- Keep top level docstrings at the top of the file, before `verus! {`. Do not place them after the `verus! {` declaration.
- Don't change any function signatures.

## Spec Functions
1. No Direct Method Calls:
   In a spec function, you cannot directly call instance methods such as vector.is_full().
2. Use the @ Operator:
   To invoke methods on a variable within a spec, first convert it to its specification-level representation View with @.
3. Always use vector.len() instead of vector@.len().
4. Simplify Boolean Conjunctions:
   When combining multiple conditions, avoid excessive &&&. Fewer (or well-structured) conjunctions make the spec code easier to read and debug.
5. Parentheses Usage:
   ALWAYS wrap conditions in parentheses, even for simple expressions. This makes precedence explicit and prevents errors.

## Proof Blocks - CRITICAL SYNTAX RULES

**üö´ NEVER use executable control flow (if/else/match) inside `proof { }` blocks!**

Proof blocks are spec-level contexts. They can only contain:
- `assert(...)` statements
- `assume(...)` statements
- Lemma/proof function calls
- Variable bindings with spec expressions

‚ùå **WRONG - Executable if/else in proof:**
```rust
proof {
    if condition { assert(x); } else { assert(y); }  // SYNTAX ERROR!
}
```

‚úÖ **CORRECT - Use implication instead:**
```rust
proof {
    assert(condition ==> x);
    assert(!condition ==> y);
}
```

‚ùå **WRONG - Executable match in proof:**
```rust
proof {
    match opt { Some(v) => assert(v > 0), None => {} }  // SYNTAX ERROR!
}
```

‚úÖ **CORRECT - Use implication or spec-level reasoning:**
```rust
proof {
    assert(opt.is_Some() ==> opt.unwrap() > 0);
}
```

## Operators
Verus extends Rust logical operators with low-precedence forms that are especially helpful in specification code:

Standard Operators: &&, ||, ==>, <==>
Low-Precedence Variants: &&& and |||

The meaning of &&& is the same as && (logical AND), and ||| is the same as || (logical OR), but with lower precedence. This allows you to write conditions in a "bulleted list" style that remains grouped in a logical manner:

```
&&& a ==> b
&&& c
&&& d <==> e && f
```

is equivalent to:

```
(a ==> b) && c && (d <==> (e && f))
```

Note:
- Implication (==>) and equivalence (<==>) bind more tightly than &&& and |||.
- Using &&&/||| can make long specifications clearer by grouping logical clauses neatly.


# Verus Match Syntax Guidelines

## Using `matches!` Macro

In Verus, the `matches!` macro must use Rust's standard macro syntax:

```rust
// CORRECT
pub open spec fn is_Some<A>(opt: MyOption<A>) -> bool {
    matches!(opt, MyOption::Some(_))
}

// INCORRECT - don't use this syntax
pub open spec fn is_Some<A>(opt: MyOption<A>) -> bool {
    matches opt {
        MyOption::Some(_) => true,
        MyOption::None => false,
    }
}
```

## Match with `arbitrary()` in Spec Functions

When writing spec functions that match on patterns with impossible/unreachable branches, use `arbitrary()` instead of `unreachable!()`:

```rust
// CORRECT
pub open spec fn get_Some_0<A>(opt: MyOption<A>) -> A
    recommends is_Some(opt)
{
    match opt {
        MyOption::Some(a) => a,
        MyOption::None => arbitrary(), // For unreachable branches in spec functions
    }
}

// INCORRECT
pub open spec fn get_Some_0<A>(opt: MyOption<A>) -> A
    recommends is_Some(opt)
{
    match opt {
        MyOption::Some(a) => a,
        MyOption::None => unreachable!(), // Don't use this in spec functions
    }
}
```

## Match in Executable Functions

For unreachable branches in executable functions, use `unreached()`:

```rust
pub fn unwrap(self) -> (a: A)
    requires
        is_Some(self),
    ensures
        a == get_Some_0(self),
{
    match self {
        MyOption::Some(a) => a,
        MyOption::None => unreached(), // For unreachable branches in exec functions
    }
}
```

## Match in Proof Functions

For unreachable branches in proof functions, use `proof_from_false()`:

```rust
pub proof fn tracked_unwrap(tracked self) -> (tracked a: A)
    requires
        is_Some(self),
    ensures
        a == get_Some_0(self),
{
    match self {
        MyOption::Some(a) => a,
        MyOption::None => proof_from_false(), // For unreachable branches in proof functions
    }
}
```


additional knowledge:


# relevant vstd lib knowledge

## builtin_macros::*;

The bit_vector solver doesn‚Äôt allow arbitrary functions. However, you can use macros. This is useful when certain operations need a common shorthand, like ‚Äúget the ith bit of an integer‚Äù.


macro_rules! get_bit_macro {
    ($a:expr, $b:expr) => {{
        (0x1u32 & ($a >> $b)) == 1
    }};
}

macro_rules! get_bit {
    ($($a:tt)*) => {
        verus_proof_macro_exprs!(get_bit_macro!($($a)*))
    }
}


verus_proof_macro_exprs!() { /* proc-macro */ }
verus_proof_macro_exprs!(f!(exprs)) applies verus syntax to transform exprs into exprs‚Äô, then returns f!(exprs‚Äô), where exprs is a sequence of expressions separated by ‚Äú,‚Äù, ‚Äú;‚Äù, and/or ‚Äú=>‚Äù.

## vstd::atomic_ghost::*;

//! Provides sequentially-consistent atomic memory locations with associated ghost state.
//! See the [`atomic_with_ghost!`] documentation for more information.
#![allow(unused_imports)]

use super::atomic::*;
use super::invariant::*;
use super::modes::*;
use super::prelude::*;

verus! {

pub trait AtomicInvariantPredicate<K, V, G> {
    spec fn atomic_inv(k: K, v: V, g: G) -> bool;
}

} // verus!
macro_rules! declare_atomic_type {
    ($at_ident:ident, $patomic_ty:ident, $perm_ty:ty, $value_ty: ty, $atomic_pred_ty: ident) => {
        verus!{

        pub struct $atomic_pred_ty<Pred> { p: Pred }

        impl<K, G, Pred> InvariantPredicate<(K, int), ($perm_ty, G)> for $atomic_pred_ty<Pred>
            where Pred: AtomicInvariantPredicate<K, $value_ty, G>
        {
            open spec fn inv(k_loc: (K, int), perm_g: ($perm_ty, G)) -> bool {
                let (k, loc) = k_loc;
                let (perm, g) = perm_g;

                perm.view().patomic == loc
                  && Pred::atomic_inv(k, perm.view().value, g)
            }
        }

        #[doc = concat!(
            "Sequentially-consistent atomic memory location storing a `",
            stringify!($value_ty),
            "` and associated ghost state."
        )]
        ///
        /// See the [`atomic_with_ghost!`] documentation for usage information.

        pub struct $at_ident<K, G, Pred>
            //where Pred: AtomicInvariantPredicate<K, $value_ty, G>
        {
            #[doc(hidden)]
            pub patomic: $patomic_ty,

            #[doc(hidden)]
            pub atomic_inv: Tracked<AtomicInvariant<(K, int), ($perm_ty, G), $atomic_pred_ty<Pred>>>,
        }

        impl<K, G, Pred> $at_ident<K, G, Pred>
            where Pred: AtomicInvariantPredicate<K, $value_ty, G>
        {
            pub open spec fn well_formed(&self) -> bool {
                self.atomic_inv@.constant().1 == self.patomic.id()
            }

            pub open spec fn constant(&self) -> K {
                self.atomic_inv@.constant().0
            }

            #[inline(always)]
            pub const fn new(Ghost(k): Ghost<K>, u: $value_ty, Tracked(g): Tracked<G>) -> (t: Self)
                requires Pred::atomic_inv(k, u, g),
                ensures t.well_formed() && t.constant() == k,
            {

                let (patomic, Tracked(perm)) = $patomic_ty::new(u);

                let tracked pair = (perm, g);
                assert(Pred::atomic_inv(k, u, g));
                assert(perm.view().patomic == patomic.id());
                let tracked atomic_inv = AtomicInvariant::new(
                    (k, patomic.id()), pair, 0);

                $at_ident {
                    patomic,
                    atomic_inv: Tracked(atomic_inv),
                }
            }

            #[inline(always)]
            pub fn load(&self) -> $value_ty
                requires self.well_formed(),
            {
                atomic_with_ghost!(self => load(); g => { })
            }

            #[inline(always)]
            pub fn into_inner(self) -> (res: ($value_ty, Tracked<G>))
                requires self.well_formed(),
                ensures Pred::atomic_inv(self.constant(), res.0, res.1@),
            {
                let Self { patomic, atomic_inv: Tracked(atomic_inv) } = self;
                let tracked (perm, g) = atomic_inv.into_inner();
                let v = patomic.into_inner(Tracked(perm));
                (v, Tracked(g))
            }
        }

        }
    };
}
macro_rules! declare_atomic_type_generic {
    ($at_ident:ident, $patomic_ty:ident, $perm_ty:ty, $value_ty: ty, $atomic_pred_ty: ident) => {
        verus!{

        pub struct $atomic_pred_ty<T, Pred> { t: T, p: Pred }

        impl<T, K, G, Pred> InvariantPredicate<(K, int), ($perm_ty, G)> for $atomic_pred_ty<T, Pred>
            where Pred: AtomicInvariantPredicate<K, $value_ty, G>
        {
            open spec fn inv(k_loc: (K, int), perm_g: ($perm_ty, G)) -> bool {
                let (k, loc) = k_loc;
                let (perm, g) = perm_g;

                perm.view().patomic == loc
                  && Pred::atomic_inv(k, perm.view().value, g)
            }
        }

        #[doc = concat!(
            "Sequentially-consistent atomic memory location storing a `",
            stringify!($value_ty),
            "` and associated ghost state."
        )]
        ///
        /// See the [`atomic_with_ghost!`] documentation for usage information.

        pub struct $at_ident<T, K, G, Pred>
            //where Pred: AtomicInvariantPredicate<K, $value_ty, G>
        {
            #[doc(hidden)]
            pub patomic: $patomic_ty<T>,

            #[doc(hidden)]
            pub atomic_inv: Tracked<AtomicInvariant<(K, int), ($perm_ty, G), $atomic_pred_ty<T, Pred>>>,
        }

        impl<T, K, G, Pred> $at_ident<T, K, G, Pred>
            where Pred: AtomicInvariantPredicate<K, $value_ty, G>
        {
            pub open spec fn well_formed(&self) -> bool {
                self.atomic_inv@.constant().1 == self.patomic.id()
            }

            pub open spec fn constant(&self) -> K {
                self.atomic_inv@.constant().0
            }

            #[inline(always)]
            pub const fn new(Ghost(k): Ghost<K>, u: $value_ty, Tracked(g): Tracked<G>) -> (t: Self)
                requires Pred::atomic_inv(k, u, g),
                ensures t.well_formed() && t.constant() == k,
            {

                let (patomic, Tracked(perm)) = $patomic_ty::<T>::new(u);

                let tracked pair = (perm, g);
                let tracked atomic_inv = AtomicInvariant::new(
                    (k, patomic.id()), pair, 0);

                $at_ident {
                    patomic,
                    atomic_inv: Tracked(atomic_inv),
                }
            }

            #[inline(always)]
            pub fn load(&self) -> $value_ty
                requires self.well_formed(),
            {
                atomic_with_ghost!(self => load(); g => { })
            }

            #[inline(always)]
            pub fn into_inner(self) -> (res: ($value_ty, Tracked<G>))
                requires self.well_formed(),
                ensures Pred::atomic_inv(self.constant(), res.0, res.1@),
            {
                let Self { patomic, atomic_inv: Tracked(atomic_inv) } = self;
                let tracked (perm, g) = atomic_inv.into_inner();
                let v = patomic.into_inner(Tracked(perm));
                (v, Tracked(g))
            }
        }

        }
    };
}

#[cfg(target_has_atomic = "64")]
declare_atomic_type!(AtomicU64, PAtomicU64, PermissionU64, u64, AtomicPredU64);

declare_atomic_type!(AtomicU32, PAtomicU32, PermissionU32, u32, AtomicPredU32);
declare_atomic_type!(AtomicU16, PAtomicU16, PermissionU16, u16, AtomicPredU16);
declare_atomic_type!(AtomicU8, PAtomicU8, PermissionU8, u8, AtomicPredU8);
declare_atomic_type!(AtomicUsize, PAtomicUsize, PermissionUsize, usize, AtomicPredUsize);

#[cfg(target_has_atomic = "64")]
declare_atomic_type!(AtomicI64, PAtomicI64, PermissionI64, i64, AtomicPredI64);

declare_atomic_type!(AtomicI32, PAtomicI32, PermissionI32, i32, AtomicPredI32);
declare_atomic_type!(AtomicI16, PAtomicI16, PermissionI16, i16, AtomicPredI16);
declare_atomic_type!(AtomicI8, PAtomicI8, PermissionI8, i8, AtomicPredI8);
declare_atomic_type!(AtomicIsize, PAtomicIsize, PermissionIsize, isize, AtomicPredIsize);

declare_atomic_type!(AtomicBool, PAtomicBool, PermissionBool, bool, AtomicPredBool);

declare_atomic_type_generic!(AtomicPtr, PAtomicPtr, PermissionPtr<T>, *mut T, AtomicPredPtr);

/// Performs a given atomic operation on a given atomic
/// while providing access to its ghost state.
///
/// `atomic_with_ghost!` supports the types
/// [`AtomicU64`] [`AtomicU32`], [`AtomicU16`], [`AtomicU8`],
/// [`AtomicI64`], [`AtomicI32`], [`AtomicI16`], [`AtomicI8`], and [`AtomicBool`].
///
/// For each type, it supports all applicable atomic operations among
/// `load`, `store`, `swap`, `compare_exchange`, `compare_exchange_weak`,
/// `fetch_add`, `fetch_add_wrapping`, `fetch_sub`, `fetch_sub_wrapping`,
/// `fetch_or`, `fetch_and`, `fetch_xor`, `fetch_nand`, `fetch_max`, and `fetch_min`.
///
/// Naturally, `AtomicBool` does not support the arithmetic-specific operations.
///
/// In general, the syntax is:
///
///     let result = atomic_with_ghost!(
///         $atomic => $operation_name($operands...);
///         update $prev -> $next;         // `update` line is optional
///         returning $ret;                // `returning` line is optional
///         ghost $g => {
///             /* Proof code with access to `tracked` variable `g: G` */
///         }
///     );
///
/// Here, the `$operation_name` is one of `load`, `store`, etc. Meanwhile,
/// `$prev`, `$next`, and `$ret` are all identifiers which
/// will be available as spec variable inside the block to describe the
/// atomic action which is performed.
///
/// For example, suppose the user performs `fetch_add(1)`. The atomic
/// operation might load the value 5, add 1, store the value 6,
/// and return the original value, 5. In that case, we would have
/// `prev == 5`, `next == 6`, and `ret == 5`.
///
/// The specification for a given operation is given as a relation between
/// `prev`, `next`, and `ret`; that is, at the beginning of the proof block,
/// the user may assume the given specification holds:
///
/// | operation                     | specification                                                                                                              |
/// |-------------------------------|----------------------------------------------------------------------------------------------------------------------------|
/// | `load()`                      | `next == prev && rev == prev`                                                                                              |
/// | `store(x)`                    | `next == x && ret == ()`                                                                                                   |
/// | `swap(x)`                     | `next == x && ret == prev`                                                                                                 |
/// | `compare_exchange(x, y)`      | `prev == x && next == y && ret == Ok(prev)` ("success") OR<br> `prev != x && next == prev && ret == Err(prev)` ("failure") |
/// | `compare_exchange_weak(x, y)` | `prev == x && next == y && ret == Ok(prev)` ("success") OR<br> `next == prev && ret == Err(prev)` ("failure")              |
/// | `fetch_add(x)` (*)            | `next == prev + x && ret == prev`                                                                                          |
/// | `fetch_add_wrapping(x)`       | `next == wrapping_add(prev, x) && ret == prev`                                                                             |
/// | `fetch_sub(x)` (*)            | `next == prev - x && ret == prev`                                                                                          |
/// | `fetch_sub_wrapping(x)`       | `next == wrapping_sub(prev, x) && ret == prev`                                                                             |
/// | `fetch_or(x)`                 | <code>next == prev \| x && ret == prev</code>                                                                              |
/// | `fetch_and(x)`                | `next == prev & x && ret == prev`                                                                                          |
/// | `fetch_xor(x)`                | `next == prev ^ x && ret == prev`                                                                                          |
/// | `fetch_nand(x)`               | `next == !(prev & x) && ret == prev`                                                                                       |
/// | `fetch_max(x)`                | `next == max(prev, x) && ret == prev`                                                                                      |
/// | `fetch_min(x)`                | `next == max(prev, x) && ret == prev`                                                                                      |
/// | `no_op()` (**)                | `next == prev && ret == ()`                                                                                                |
///
/// (*) Note that `fetch_add` and `fetch_sub` do not specify
/// wrapping-on-overflow; instead, they require the user to
/// prove that overflow _does not occur_, i.e., the user must show
/// that `next` is in bounds for the integer type in question.
/// Furthermore, for `fetch_add` and `fetch_sub`, the spec values of
/// `prev`, `next`, and `ret` are all given with type `int`, so the
/// user may reason about boundedness within the proof block.
///
/// (As executable code, `fetch_add` is equivalent to `fetch_add_wrapping`,
/// and likewise for `fetch_sub` and `fetch_sub_wrapping`.
/// We have both because it's frequently the case that the user needs to verify
/// lack-of-overflow _anyway_, and having it as an explicit precondition by default
/// then makes verification errors easier to diagnose. Furthermore, when overflow is
/// intended, the wrapping operations document that intent.)
///
/// (**) `no_op` is entirely a ghost operation and doesn't emit any actual instruction.
/// This allows the user to access the ghost state and the stored value (as `spec` data)
/// without actually performing a load.
///
/// ---
///
/// At the beginning of the proof block, the user may assume, in addition
/// to the specified relation between `prev`, `next`, and `ret`, that
/// `atomic.inv(prev, g)` holds. The user is required to update `g` such that
/// `atomic.inv(next, g)` holds at the end of the block.
/// In other words, the ghost block has the implicit pre- and post-conditions:
///
///     let result = atomic_with_ghost!(
///         $atomic => $operation_name($operands...);
///         update $prev -> $next;
///         returning $ret;
///         ghost $g => {
///             assume(specified relation on (prev, next, ret));
///             assume(atomic.inv(prev, g));
///
///             // User code here; may update variable `g` with full
///             // access to variables in the outer context.
///
///             assert(atomic.inv(next, g));
///         }
///     );
///
/// Note that the necessary action on ghost state might depend
/// on the result of the operation; for example, if the user performs a
/// compare-and-swap, then the ghost action that they then need to do
/// will probably depend on whether the operation succeeded or not.
///
/// The value returned by the `atomic_with_ghost!(...)` expression will be equal
/// to `ret`, although the return value is an `exec` value (the actual result of
/// the operation) while `ret` is a `spec` value.
///
/// ### Example (TODO)

#[macro_export]
macro_rules! atomic_with_ghost {
    ($($tokens:tt)*) => {
        // The helper is used to parse things using Verus syntax
        // The helper then calls atomic_with_ghost_inner, below:
        ::builtin_macros::atomic_with_ghost_helper!(
            $crate::vstd::atomic_ghost::atomic_with_ghost_inner,
            $($tokens)*)
    }
}

pub use atomic_with_ghost;

#[doc(hidden)]
#[macro_export]
macro_rules! atomic_with_ghost_inner {
    (load, $e:expr, (), $prev:pat, $next:pat, $ret:pat, $g:ident, $b:block) => {
        $crate::vstd::atomic_ghost::atomic_with_ghost_load!($e, $prev, $next, $ret, $g, $b)
    };
    (store, $e:expr, ($operand:expr), $prev:pat, $next:pat, $ret:pat, $g:ident, $b:block) => {
        $crate::vstd::atomic_ghost::atomic_with_ghost_store!(
            $e, $operand, $prev, $next, $ret, $g, $b
        )
    };
    (swap, $e:expr, ($operand:expr), $prev:pat, $next:pat, $ret:pat, $g:ident, $b:block) => {
        $crate::vstd::atomic_ghost::atomic_with_ghost_update_with_1_operand!(
            swap, $e, $operand, $prev, $next, $ret, $g, $b
        )
    };

    (fetch_or, $e:expr, ($operand:expr), $prev:pat, $next:pat, $ret:pat, $g:ident, $b:block) => {
        $crate::vstd::atomic_ghost::atomic_with_ghost_update_with_1_operand!(
            fetch_or, $e, $operand, $prev, $next, $ret, $g, $b
        )
    };
    (fetch_and, $e:expr, ($operand:expr), $prev:pat, $next:pat, $ret:pat, $g:ident, $b:block) => {
        $crate::vstd::atomic_ghost::atomic_with_ghost_update_with_1_operand!(
            fetch_and, $e, $operand, $prev, $next, $ret, $g, $b
        )
    };
    (fetch_xor, $e:expr, ($operand:expr), $prev:pat, $next:pat, $ret:pat, $g:ident, $b:block) => {
        $crate::vstd::atomic_ghost::atomic_with_ghost_update_with_1_operand!(
            fetch_xor, $e, $operand, $prev, $next, $ret, $g, $b
        )
    };
    (fetch_nand, $e:expr, ($operand:expr), $prev:pat, $next:pat, $ret:pat, $g:ident, $b:block) => {
        $crate::vstd::atomic_ghost::atomic_with_ghost_update_with_1_operand!(
            fetch_nand, $e, $operand, $prev, $next, $ret, $g, $b
        )
    };
    (fetch_max, $e:expr, ($operand:expr), $prev:pat, $next:pat, $ret:pat, $g:ident, $b:block) => {
        $crate::vstd::atomic_ghost::atomic_with_ghost_update_with_1_operand!(
            fetch_max, $e, $operand, $prev, $next, $ret, $g, $b
        )
    };
    (fetch_min, $e:expr, ($operand:expr), $prev:pat, $next:pat, $ret:pat, $g:ident, $b:block) => {
        $crate::vstd::atomic_ghost::atomic_with_ghost_update_with_1_operand!(
            fetch_min, $e, $operand, $prev, $next, $ret, $g, $b
        )
    };
    (fetch_add_wrapping, $e:expr, ($operand:expr), $prev:pat, $next:pat, $ret:pat, $g:ident, $b:block) => {
        $crate::vstd::atomic_ghost::atomic_with_ghost_update_with_1_operand!(
            fetch_add_wrapping,
            $e,
            $operand,
            $prev,
            $next,
            $ret,
            $g,
            $b
        )
    };
    (fetch_sub_wrapping, $e:expr, ($operand:expr), $prev:pat, $next:pat, $ret:pat, $g:ident, $b:block) => {
        $crate::vstd::atomic_ghost::atomic_with_ghost_update_with_1_operand!(
            fetch_sub_wrapping,
            $e,
            $operand,
            $prev,
            $next,
            $ret,
            $g,
            $b
        )
    };

    (fetch_add, $e:expr, ($operand:expr), $prev:pat, $next:pat, $ret:pat, $g:ident, $b:block) => {
        $crate::vstd::atomic_ghost::atomic_with_ghost_update_fetch_add!(
            $e, $operand, $prev, $next, $ret, $g, $b
        )
    };
    (fetch_sub, $e:expr, ($operand:expr), $prev:pat, $next:pat, $ret:pat, $g:ident, $b:block) => {
        $crate::vstd::atomic_ghost::atomic_with_ghost_update_fetch_sub!(
            $e, $operand, $prev, $next, $ret, $g, $b
        )
    };

    (compare_exchange, $e:expr, ($operand1:expr, $operand2:expr), $prev:pat, $next:pat, $ret:pat, $g:ident, $b:block) => {
        $crate::vstd::atomic_ghost::atomic_with_ghost_update_with_2_operand!(
            compare_exchange,
            $e,
            $operand1,
            $operand2,
            $prev,
            $next,
            $ret,
            $g,
            $b
        )
    };
    (compare_exchange_weak, $e:expr, ($operand1:expr, $operand2:expr), $prev:pat, $next:pat, $ret:pat, $g:ident, $b:block) => {
        $crate::vstd::atomic_ghost::atomic_with_ghost_update_with_2_operand!(
            compare_exchange_weak,
            $e,
            $operand1,
            $operand2,
            $prev,
            $next,
            $ret,
            $g,
            $b
        )
    };
    (no_op, $e:expr, (), $prev:pat, $next:pat, $ret:pat, $g:ident, $b:block) => {
        $crate::vstd::atomic_ghost::atomic_with_ghost_no_op!($e, $prev, $next, $ret, $g, $b)
    };
}

pub use atomic_with_ghost_inner;

#[doc(hidden)]
#[macro_export]
macro_rules! atomic_with_ghost_store {
    ($e:expr, $operand:expr, $prev:pat, $next:pat, $res:pat, $g:ident, $b:block) => {
        ::builtin_macros::verus_exec_expr! { {
            let atomic = &($e);
            $crate::vstd::invariant::open_atomic_invariant!(atomic.atomic_inv.borrow() => pair => {
                #[allow(unused_mut)]
                let tracked (mut perm, mut $g) = pair;
                let ghost $prev = perm.view().value;
                atomic.patomic.store(Tracked(&mut perm), $operand);
                let ghost $next = perm.view().value;
                let ghost $res = ();

                proof { $b }

                proof { pair = (perm, $g); }
            });
        } }
    };
}
pub use atomic_with_ghost_store;

#[doc(hidden)]
#[macro_export]
macro_rules! atomic_with_ghost_load {
    ($e:expr, $prev:pat, $next: pat, $res: pat, $g:ident, $b:block) => {
        ::builtin_macros::verus_exec_expr! { {
            let result;
            let atomic = &($e);
            $crate::vstd::invariant::open_atomic_invariant!(atomic.atomic_inv.borrow() => pair => {
                #[allow(unused_mut)]
                let tracked (perm, mut $g) = pair;
                result = atomic.patomic.load(Tracked(&perm));
                let ghost $res = result;
                let ghost $prev = result;
                let ghost $next = result;

                proof { $b }

                proof { pair = (perm, $g); }
            });
            result
        } }
    };
}

pub use atomic_with_ghost_load;

#[doc(hidden)]
#[macro_export]
macro_rules! atomic_with_ghost_no_op {
    ($e:expr, $prev:pat, $next: pat, $res: pat, $g:ident, $b:block) => {
        ::builtin_macros::verus_exec_expr! { {
            let atomic = &($e);
            $crate::vstd::invariant::open_atomic_invariant!(atomic.atomic_inv.borrow() => pair => {
                #[allow(unused_mut)]
                let tracked (perm, mut $g) = pair;
                let ghost result = perm.view().value;
                let ghost $res = result;
                let ghost $prev = result;
                let ghost $next = result;

                proof { $b }

                proof { pair = (perm, $g); }
            });
        } }
    };
}

pub use atomic_with_ghost_no_op;

#[doc(hidden)]
#[macro_export]
macro_rules! atomic_with_ghost_update_with_1_operand {
    ($name:ident, $e:expr, $operand:expr, $prev:pat, $next:pat, $res: pat, $g:ident, $b:block) => {
        ::builtin_macros::verus_exec_expr! { {
            let result;
            let atomic = &($e);
            let operand = $operand;
            $crate::vstd::invariant::open_atomic_invariant!(atomic.atomic_inv.borrow() => pair => {
                #[allow(unused_mut)]
                let tracked (mut perm, mut $g) = pair;
                let ghost $prev = perm.view().value;
                result = atomic.patomic.$name(Tracked(&mut perm), operand);
                let ghost $res = result;
                let ghost $next = perm.view().value;

                proof { $b }

                proof { pair = (perm, $g); }
            });
            result
        } }
    };
}

pub use atomic_with_ghost_update_with_1_operand;

#[doc(hidden)]
#[macro_export]
macro_rules! atomic_with_ghost_update_with_2_operand {
    ($name:ident, $e:expr, $operand1:expr, $operand2:expr, $prev:pat, $next:pat, $res: pat, $g:ident, $b:block) => {
        ::builtin_macros::verus_exec_expr! { {
            let result;
            let atomic = &($e);
            let operand1 = $operand1;
            let operand2 = $operand2;
            $crate::vstd::invariant::open_atomic_invariant!(atomic.atomic_inv.borrow() => pair => {
                #[allow(unused_mut)]
                let tracked (mut perm, mut $g) = pair;
                let ghost $prev = perm.view().value;
                result = atomic.patomic.$name(Tracked(&mut perm), operand1, operand2);
                let ghost $res = result;
                let ghost $next = perm.view().value;

                proof { $b }

                proof { pair = (perm, $g); }
            });
            result
        } }
    };
}

pub use atomic_with_ghost_update_with_2_operand;

#[doc(hidden)]
#[macro_export]
macro_rules! atomic_with_ghost_update_fetch_add {
    ($e:expr, $operand:expr, $prev:pat, $next:pat, $res: pat, $g:ident, $b:block) => {
        (::builtin_macros::verus_exec_expr!( {
            let result;
            let atomic = &($e);
            let operand = $operand;
            $crate::vstd::invariant::open_atomic_invariant!(atomic.atomic_inv.borrow() => pair => {
                #[allow(unused_mut)]
                let tracked (mut perm, mut $g) = pair;

                proof {
                    let $prev = perm.view().value as int;
                    let $res = perm.view().value as int;
                    let $next = perm.view().value as int + (operand as int);

                    { $b }
                }

                result = atomic.patomic.fetch_add(Tracked(&mut perm), operand);

                proof { pair = (perm, $g); }
            });
            result
        } ))
    }
}

pub use atomic_with_ghost_update_fetch_add;

#[doc(hidden)]
#[macro_export]
macro_rules! atomic_with_ghost_update_fetch_sub {
    ($e:expr, $operand:expr, $prev:pat, $next:pat, $res: pat, $g:ident, $b:block) => {
        ::builtin_macros::verus_exec_expr! { {
            let result;
            let atomic = &($e);
            let operand = $operand;
            $crate::vstd::invariant::open_atomic_invariant!(atomic.atomic_inv.borrow() => pair => {
                #[allow(unused_mut)]
                let tracked (mut perm, mut $g) = pair;

                proof {
                    let $prev = perm.view().value as int;
                    let $res = perm.view().value as int;
                    let $next = perm.view().value as int - (operand as int);

                    { $b }
                }

                result = atomic.patomic.fetch_sub(Tracked(&mut perm), operand);

                proof { pair = (perm, $g); }
            });
            result
        } }
    };
}

pub use atomic_with_ghost_update_fetch_sub;


## verification_plan

No plan generated. Proceeding with default execution order.



## Exemplars

### Example 1

## Query
Example 1: Pattern for writing proofs and loop invariants

## Answer
use vstd::prelude::*;
fn main() {}

verus! {
    spec fn sorted_between(a: Seq<u32>, from: int, to: int) -> bool {
        forall |i: int, j:int|  from <= i < j < to ==> a[i] <= a[j]
    }


    spec fn is_reorder_of<T>(r: Seq<int>, p: Seq<T>, s: Seq<T>) -> bool {
    &&& r.len() == s.len()
    &&& forall|i: int| 0 <= i < r.len() ==> 0 <= #[trigger] r[i] < r.len()
    &&& forall|i: int, j: int| 0 <= i < j < r.len() ==> r[i] != r[j]
    &&& p =~= r.map_values(|i: int| s[i])
    }

    fn test1(nums: &mut Vec<u32>)
        ensures
            sorted_between(nums@, 0, nums@.len() as int),
            exists|r: Seq<int>| is_reorder_of(r, nums@, old(nums)@),
    {
        let ghost mut r = Seq::new(nums@.len(), |i: int| i);
        assert(is_reorder_of(r, nums@, nums@));
        let n = nums.len();
        if n == 0 {
            return;
        }
        for i in 1..n
            // ========== INFERRED INVARIANTS ==========
            invariant
                n == nums.len(),
                sorted_between(nums@, 0, i as int),
                is_reorder_of(r, nums@, old(nums)@),
            // =========================================
        {
            let mut j = i;
            while j != 0
                // ========== INFERRED INVARIANTS ==========
                invariant
                    0 <= j <= i < n == nums.len(),
                    forall|x: int, y: int| 0 <= x <= y <= i ==> x != j && y != j ==> nums[x] <= nums[y],
                    sorted_between(nums@, j as int, i + 1),
                    is_reorder_of(r, nums@, old(nums)@),
                // =========================================
            {
                if nums[j - 1] > nums[j] {
                    let temp = nums[j - 1];
                    nums.set(j - 1, nums[j]);
                    nums.set(j, temp);
                    // ========== INFERRED PROOF ==========
                    proof {
                        r = r.update(j - 1, r[j as int]).update(j as int, r[j - 1]);
                        assert(is_reorder_of(r, nums@, old(nums)@));
                    }
                    // ====================================
                }
                j -= 1;
            }
        }
    }
}


### Example 2

## Query
Example 2: Pattern for writing proofs and loop invariants

## Answer
use vstd::prelude::*;
fn main() {}
verus!{

pub fn myfun(a: &mut Vec<u32>, N: u32) -> (sum: u32)
	requires
		old(a).len() == N,
		N <= 0x7FFF_FFFF,
	ensures
	    sum <= 2*N,
{
	let mut i: usize = 0;
	while (i < N as usize)
	// ========== INFERRED INVARIANTS ==========
	invariant
	    i<=N,
	    a.len()==N,
	    forall|j:int| 0<=j<i ==> a[j]<=2,
	// =========================================
	{
		if (a[i] > 2) {
			a.set(i, 2);
		}
		i = i + 1;
	}

    // ========== INFERRED ASSERTION ==========
    assert(forall|j:int| 0<=j<N ==> a[j]<=2);
    // ========================================

	i = 0;
    let mut sum: u32 = 0;

	while (i < N as usize)
	// ========== INFERRED INVARIANTS ==========
	invariant
	    i<=N,
	    N <= 0x7FFF_FFFF,
	    a.len()==N,
	    forall|j:int| 0<=j<N ==> a[j]<=2,
	    sum<=2 * i,
	// =========================================
	{
        sum = sum + a[i];
		i = i + 1;
	}

    sum

}
}


### Example 3

## Query
Example 3: Pattern for writing proofs and loop invariants

## Answer
proof fn proof_int(x: u64) -> (tracked y: u64)
    ensures
        x == y,
{
    assume(false);
    proof_from_false()
}


### Example 4

## Query
Example 4: Pattern for writing proofs and loop invariants

## Answer
fn reverse(v: &mut Vec<u64>)
    ensures
        v.len() == old(v).len(),
        forall|i: int| 0 <= i < old(v).len() ==> v[i] == old(v)[old(v).len() - i - 1],
{
    let length = v.len();
    let ghost v1 = v@;
    for n in 0..(length / 2)
        // ========== INFERRED INVARIANTS ==========
        invariant
            length == v.len(),
            forall|i: int| 0 <= i < n ==> v[i] == v1[length - i - 1],
            forall|i: int| 0 <= i < n ==> v1[i] == v[length - i - 1],
            forall|i: int| n <= i && i + n < length ==> #[trigger] v[i] == v1[i],
        // =========================================
    {
        let x = v[n];
        let y = v[length - 1 - n];
        v.set(n, y);
        v.set(length - 1 - n, x);
    }
}


### Example 5

## Query
Example 5: Pattern for writing proofs and loop invariants

## Answer
use vstd::prelude::*;

verus! {

proof fn combine_proof(item1: ItemType, item2: ItemType, result: ItemType)
    requires
        result == combine_items(item1, item2),
    ensures
        // ... properties about the combined result ...
{
}

pub struct Container {
    items: Vec<ItemType>,
}

impl Container {
    spec fn view(&self) -> Seq<ViewType> {
        // ... converts items to view representation ...
    }

    fn combine(&self, other: &Container) -> (ret: Container)
        requires
            self@.len() == other@.len(),
        ensures
            ret@.len() == self@.len(),
            forall|i: int| #![auto] 0 <= i < ret@.len() ==>
                ret@[i] == combine_operation(self@[i], other@[i]),
    {
        let n: usize = self.items.len();
        let mut i: usize = 0;
        let mut result_items: Vec<ItemType> = Vec::new();
        let mut result = Container { items: result_items };
        while i < n
            // ========== INFERRED INVARIANTS ==========
            invariant
                i <= n,
                // CRITICAL: Connect loop bound to actual vector lengths
                n == self.items@.len(),
                n == other.items@.len(),
                i == result.items.len(),
                // CRITICAL: State the property at abstract (view) level
                forall|k: int| #![auto] 0 <= k < result@.len() ==>
                    result@[k] == combine_operation(self@[k], other@[k]),
            // =========================================
        {
            result_items = result.items;
            let item1: ItemType = self.items[i];
            let item2: ItemType = other.items[i];
            let combined: ItemType = combine_items(item1, item2);
            // ========== INFERRED PROOF ==========
            proof {
                combine_proof(item1, item2, combined);
                // Keep proof blocks simple - just call the proof function
                // The loop invariant does most of the work
            }
            // ====================================
            result_items.push(combined);
            result = Container { items: result_items };
            i = i + 1;
        }
        result
    }
}

} // verus!



### Example 6

## Query
Example 6: Pattern for writing proofs and loop invariants

## Answer
#![cfg_attr(verus_keep_ghost, verifier::exec_allows_no_decreases_clause)]
use vstd::prelude::*;
fn main() {}

verus! {

/// Example demonstrating correct patterns for Option types and tree-like data structures
/// Key patterns illustrated:
/// 1. Correct Option methods: is_none(), is_some(), unwrap() (NOT is_None, get_Some_0)
/// 2. Correct old() placement: *old(ptr) (NOT old(*ptr))
/// 3. Ensures clauses: inline expressions (NO let...in syntax)
/// 4. When no View trait: use explicit .to_map() calls (NOT self@)

pub struct TreeNode<T> {
    pub id: u64,
    pub data: T,
    pub left: Option<Box<TreeNode<T>>>,
    pub right: Option<Box<TreeNode<T>>>,
}

impl<T> TreeNode<T> {
    /// Spec function to convert tree to map (NO View trait, so use explicit calls)
    pub closed spec fn to_map(self) -> Map<u64, T>
        decreases self,
    {
        TreeNode::<T>::opt_to_map(self.left)
            .union_prefer_right(TreeNode::<T>::opt_to_map(self.right))
            .insert(self.id, self.data)
    }

    pub closed spec fn opt_to_map(tree_opt: Option<Box<TreeNode<T>>>) -> Map<u64, T>
        decreases tree_opt,
    {
        match tree_opt {
            None => Map::empty(),
            Some(tree) => tree.to_map(),
        }
    }

    pub closed spec fn is_valid(self) -> bool
        decreases self
    {
        &&& (forall |elem| TreeNode::<T>::opt_to_map(self.left).dom().contains(elem) ==> elem < self.id)
        &&& (forall |elem| TreeNode::<T>::opt_to_map(self.right).dom().contains(elem) ==> elem > self.id)
        &&& (match self.left {
            Some(left_child) => left_child.is_valid(),
            None => true,
        })
        &&& (match self.right {
            Some(right_child) => right_child.is_valid(),
            None => true,
        })
    }

    /// CORRECT PATTERN: Option methods and ensures clauses
    pub fn add_to_optional(ptr: &mut Option<Box<TreeNode<T>>>, id: u64, data: T)
        requires
            // ‚úÖ CORRECT: Use is_some() and unwrap() (lowercase, standard Rust)
            old(ptr).is_some() ==> old(ptr).unwrap().is_valid(),
        ensures
            // ‚úÖ CORRECT: Use is_some() and unwrap()
            ptr.is_some() ==> ptr.unwrap().is_valid(),
            // ‚úÖ CORRECT: *old(ptr) not old(*ptr)
            // ‚úÖ CORRECT: Inline expression, no let...in
            TreeNode::<T>::opt_to_map(*ptr) =~=
                TreeNode::<T>::opt_to_map(*old(ptr)).insert(id, data)
    {
        // ‚úÖ CORRECT: is_none() method (lowercase)
        if ptr.is_none() {
            *ptr = Some(Box::new(TreeNode::<T> {
                id: id,
                data: data,
                left: None,
                right: None,
            }));
        } else {
            let mut tmp = None;
            std::mem::swap(&mut tmp, ptr);
            let mut boxed = tmp.unwrap();
            (&mut *boxed).add(id, data);
            *ptr = Some(boxed);
        }
    }

    /// CORRECT PATTERN: Ensures with explicit method calls (no View trait)
    pub fn add(&mut self, id: u64, data: T)
        requires
            old(self).is_valid(),
        ensures
            self.is_valid(),
            // ‚úÖ CORRECT: Use .to_map() explicitly (no View trait, so no @)
            self.to_map() =~= old(self).to_map().insert(id, data),
    {
        if id == self.id {
            self.data = data;

            // ========== INFERRED PROOF ==========
            proof {
                assert(!TreeNode::<T>::opt_to_map(self.left).dom().contains(id));
                assert(!TreeNode::<T>::opt_to_map(self.right).dom().contains(id));
            }
            // ====================================
        } else if id < self.id {
            Self::add_to_optional(&mut self.left, id, data);

            // ========== INFERRED PROOF ==========
            proof {
                assert(!TreeNode::<T>::opt_to_map(self.right).dom().contains(id));
            }
            // ====================================
        } else {
            Self::add_to_optional(&mut self.right, id, data);

            // ========== INFERRED PROOF ==========
            proof {
                assert(!TreeNode::<T>::opt_to_map(self.left).dom().contains(id));
            }
            // ====================================
        }
    }

    /// CORRECT PATTERN: Complex ensures without let...in
    pub fn remove_max(ptr: &mut Option<Box<TreeNode<T>>>) -> (result: (u64, T))
        requires
            // ‚úÖ CORRECT: is_some() and unwrap()
            old(ptr).is_some(),
            old(ptr).unwrap().is_valid(),
        ensures
            ptr.is_some() ==> ptr.unwrap().is_valid(),
            // ‚úÖ CORRECT: *old(ptr) not old(*ptr)
            // ‚úÖ CORRECT: Inline all expressions, NO let...in syntax
            TreeNode::<T>::opt_to_map(*ptr) =~=
                TreeNode::<T>::opt_to_map(*old(ptr)).remove(result.0),
            TreeNode::<T>::opt_to_map(*old(ptr)).dom().contains(result.0),
            TreeNode::<T>::opt_to_map(*old(ptr))[result.0] == result.1,
            forall |elem| TreeNode::<T>::opt_to_map(*old(ptr)).dom().contains(elem) ==>
                result.0 >= elem,
    {
        let mut tmp = None;
        std::mem::swap(&mut tmp, ptr);
        let mut boxed = tmp.unwrap();

        // ‚úÖ CORRECT: is_none() method
        if boxed.right.is_none() {
            *ptr = boxed.left;

            // ========== INFERRED PROOF ==========
            proof {
                assert(TreeNode::<T>::opt_to_map(boxed.right) =~= Map::empty());
                assert(!TreeNode::<T>::opt_to_map(boxed.left).dom().contains(boxed.id));
            }
            // ====================================

            return (boxed.id, boxed.data);
        } else {
            let (max_id, max_data) = TreeNode::<T>::remove_max(&mut boxed.right);

            // ========== INFERRED PROOF ==========
            proof {
                assert(!TreeNode::<T>::opt_to_map(boxed.left).dom().contains(max_id));
            }
            // ====================================

            *ptr = Some(boxed);
            return (max_id, max_data);
        }
    }
}

}


### Example 7

## Query
Example 7: Pattern for writing proofs and loop invariants

## Answer
use vstd::prelude::*;
fn main() {}

verus! {
    pub struct Chunked {
        chunks: Vec<u64>,
        len_bits: usize,
    }

    impl Chunked {
        pub closed spec fn view(&self) -> Seq<bool> {
            let n_bits = self.len_bits as int;
            Seq::new(n_bits, |k: int| {
                let chunk = (k / 64) as int;
                let off   = (k % 64) as int;
                if 0 <= chunk && chunk < self.chunks@.len() {
                    get_bit64(self.chunks@[chunk], off as u64)
                } else { false }
            })
        }
    }

    spec fn view_from(chunks: Seq<u64>, len_bits: int) -> Seq<bool> {
        Seq::new(len_bits, |k: int| {
            let chunk = (k / 64) as int;
            let off   = (k % 64) as int;
            if 0 <= chunk && chunk < chunks.len() { get_bit64(chunks[chunk], off as u64) } else { false }
        })
    }

    spec fn combine(a: bool, b: bool) -> bool { a || b }

    proof fn chunk_op_lemma(a: u64, b: u64, r: u64, off: int)
        requires 0 <= off < 64
        ensures get_bit64(r, off as u64) == combine(get_bit64(a, off as u64), get_bit64(b, off as u64))
    { }

    pub fn combine_into(a: &Chunked, b: &Chunked) -> (c: Chunked)
        requires a@.len() == b@.len()
        ensures
            c@.len() == a@.len(),
            forall|k: int| #![auto] 0 <= k < c@.len() ==> c@[k] == combine(a@[k], b@[k])
    {
        let n_chunks = a.chunks.len();
        let mut out_chunks: Vec<u64> = Vec::new();
        out_chunks.reserve(n_chunks);
        let mut i: usize = 0;
        while i < n_chunks
            // ========== INFERRED INVARIANTS ==========
            invariant
                0 <= i as int <= n_chunks as int,
                out_chunks@.len() == i as int,
                a@.len() == b@.len() == a.len_bits as int,
                forall|k: int| #![auto]
                    0 <= k < i as int * 64 ==>
                    view_from(out_chunks@, a.len_bits as int)[k] == combine(a@[k], b@[k]),
            decreases n_chunks as int - i as int
            // =========================================
        {
            let a_chunk = a.chunks[i];
            let b_chunk = b.chunks[i];
            let r_chunk = a_chunk | b_chunk;
            out_chunks.push(r_chunk);

            // ========== INFERRED PROOF ==========
            proof {
                assert forall|off: int| 0 <= off < 64 implies
                    view_from(out_chunks@, a.len_bits as int)[i as int * 64 + off]
                        == combine(a@[i as int * 64 + off], b@[i as int * 64 + off])
                by {
                    chunk_op_lemma(a_chunk, b_chunk, r_chunk, off);
                }
            }
            // ====================================

            i += 1;
        }

        Chunked { chunks: out_chunks, len_bits: a.len_bits }
    }
}




### Example 8

## Query
Example 8: Pattern for writing proofs and loop invariants

## Answer
pub fn insert(&mut self, v: u64)
ensures
    self@ =~= old(self)@.insert(v),
{
    self.vt.push(v);
    // ========== INFERRED PROOF ==========
    proof {
        broadcast use group_seq_properties;
        assert(self.vt@ =~= old(self).vt@ + seq![v]);
    }
    // ====================================
}


### Example 9

## Query
Example 9: Pattern for writing proofs and loop invariants

## Answer
use vstd::prelude::*;

verus! {

pub struct VecWrapper {
    data: Vec<u64>,
}

impl VecWrapper {
    spec fn view(&self) -> Seq<u64> {
        self.data@
    }

    fn elementwise_or(&self, other: &VecWrapper) -> (ret: VecWrapper)
        requires
            self@.len() == other@.len(),
        ensures
            ret@.len() == self@.len(),
            forall|i: int| #![auto] 0 <= i < ret@.len() ==>
                ret@[i] == (self@[i] | other@[i]),
    {
        let n: usize = self.data.len();
        let mut i: usize = 0;
        let mut result_data: Vec<u64> = Vec::new();
        let mut result = VecWrapper { data: result_data };
        while i < n
            // ========== INFERRED INVARIANTS ==========
            invariant
                i <= n,
                // CRITICAL PATTERN: Connect loop variable to vector lengths
                // This allows Verus to prove self.data[i] and other.data[i] are safe
                n == self.data@.len(),
                n == other.data@.len(),
                i == result.data.len(),
                // State correctness property at view level
                forall|k: int| #![auto] 0 <= k < i ==>
                    result@[k] == (self@[k] | other@[k]),
            // =========================================
        {
            result_data = result.data;
            let val1: u64 = self.data[i];
            let val2: u64 = other.data[i];
            let combined: u64 = val1 | val2;
            // ========== INFERRED PROOF ==========
            proof {
                // PATTERN: For simple operations, just reference the invariant
                // No need for complex assert forall statements
                // The invariant already captures what we need
            }
            // ====================================
            result_data.push(combined);
            result = VecWrapper { data: result_data };
            i = i + 1;
        }
        result
    }
}

} // verus!












### Example 10

## Query
Example 10: Pattern for writing proofs and loop invariants

## Answer
use vstd::prelude::*;
fn main() {}

verus! {

fn reverse(v: &mut Vec<u64>)
    ensures
        v.len() == old(v).len(),
        forall|i: int| 0 <= i < old(v).len() ==> v[i] == old(v)[old(v).len() - i - 1],
{
    let length = v.len();
    let ghost v1 = v@;
    for n in 0..(length / 2)
        // ========== INFERRED INVARIANTS ==========
        invariant
            length == v.len(),
            forall|i: int| 0 <= i < n ==> v[i] == v1[length - i - 1],
            forall|i: int| 0 <= i < n ==> v1[i] == v[length - i - 1],
            forall|i: int| n <= i && i + n < length ==> #[trigger] v[i] == v1[i],
        // =========================================
    {
        let x = v[n];
        let y = v[length - 1 - n];
        v.set(n, y);
        v.set(length - 1 - n, x);
    }
}

}



## Query
#![allow(unused_imports)]
use builtin::*;
use builtin_macros::*;
use vstd::atomic_ghost::*;
use vstd::prelude::*;
use vstd::{pervasive::*, *};

verus! {

struct_with_invariants!{
/// A lock implementation using atomic boolean operations.
///
/// This lock structure provides a way to safely share data of type `T` between threads
/// using atomic operations. The lock maintains an invariant that the boolean state
/// matches whether the contained value is Some or None.
///
/// # Type Parameters
/// * `T` - The type of data protected by the lock
    struct Lock<T> {
        field: AtomicBool<_, Option<T>, _>,
    }

    spec fn well_formed(&self) -> bool {
        invariant on field with () is (b: bool, t: Option<T>) {
            // TODO: add specification
        }
    }
}

#[verifier::exec_allows_no_decreases_clause]
/// Given that the lock is well formed, the procedure attempts to take the value from the lock, spinning until successful.
///
/// In detail, it accepts a well-formed lock, and will repeatedly try to atomically swap the lock's state from true to false,
/// taking ownership of the contained value when successful. It spins in a loop until
/// it successfully acquires the lock.
///
/// # Parameters
/// * `lock` - Reference to the lock containing the value to take
///
/// # Returns
/// * A tracked value of type T that was contained in the lock
fn take<T>(lock: &Lock<T>) -> (t: Tracked<T>)
    // TODO: add requires and ensures
{
    loop
        // TODO: add invariants
    {
        let tracked ghost_value: Option<T>;
        let result =
            atomic_with_ghost!(
            &lock.field => compare_exchange(true, false);
            update prev -> next;
            ghost g => {
                if prev == true {
                    ghost_value = g;
                    g = Option::None;
                } else {
                    ghost_value = Option::None;
                }
            }
        );
        if let Result::Ok(_) = result {
            return Tracked(
                match ghost_value {
                    Option::Some(s) => s,
                    _ => { proof_from_false() },
                },
            );
        }
    }
}

/// A predicate type that enforces equality between visible and ghost state in atomic operations.
///
/// This struct implements the AtomicInvariantPredicate trait to maintain the invariant
/// that the visible value (v) equals the ghost value (g) in atomic operations.
struct VEqualG {}

impl AtomicInvariantPredicate<(), u64, u64> for VEqualG {
    closed spec fn atomic_inv(k: (), v: u64, g: u64) -> bool {
        // TODO: add specification
    }
}

proof fn proof_int(x: u64) -> (tracked y: u64)
    ensures
        x == y,
{
    assume(false);
    proof_from_false()
}


/* TEST CODE BELOW */

pub fn test() {

    let ato = AtomicU64::<(), u64, VEqualG>::new(Ghost(()), 10u64, Tracked(10u64));

    atomic_with_ghost!(ato => fetch_or(19u64);  ghost g => { g = proof_int(g | 19u64); });
    atomic_with_ghost!(ato => fetch_or(23u64);  update old_val -> new_val; ghost g => {
        assert(new_val == old_val | 23u64);
        assert(g == old_val);
        g = proof_int(g | 23u64);
        assert(g == new_val);
    });

    let res = atomic_with_ghost!(ato => compare_exchange(20u64, 25u64);
        update old_val -> new_val;
        returning ret;
        ghost g => {
            assert(imply(matches!(ret, Ok(_)), old_val == 20u64 && new_val == 25u64));
            assert(imply(matches!(ret, Err(_)), old_val != 20u64 && new_val == old_val
                         && ret->Err_0 == old_val));
            g = if g == 20u64 { proof_int(25u64) } else { g };
    });

    let res = atomic_with_ghost!(ato => load();
        returning ret;
        ghost g => { assert(ret == g); });

    atomic_with_ghost!(ato => store(36u64);
        update old_val -> new_val;
        ghost g => {
            assert(old_val == g);
            assert(new_val == 36u64);
            g = proof_int(36u64);
    });
}

pub fn main() {
}

} // verus!
